/**
 * Llama Engine - Ù…Ø­Ø±Ùƒ Llama Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ Ù…Ø¹ Few-shot Learning
 * ÙŠØ³ØªØ®Ø¯Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙØ¹Ù„ÙŠØ© Ù…Ù† sevenai_training_data.jsonl
 */

import { invokeLLM } from "./_core/llm";
import { getUserFacts } from "./db";

// Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
import { getAllTrainingData } from './training-data-advanced';

const TRAINING_EXAMPLES = getAllTrainingData();

// Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© 2024-2025
const KNOWLEDGE_2024_2025 = `
**Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø­Ø¯Ø«Ø© (2024-2025):**

Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:
- GPT-4o Ùˆ GPT-4 Turbo (Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ³Ø§Ø¦Ø·)
- Claude 3 (Opus, Sonnet, Haiku)
- Gemini (Ø³ÙŠØ§Ù‚ Ù…Ù„ÙŠÙˆÙ† token)
- Llama 3.1 (Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø±ØŒ 405B parameters)
- Sora (ØªÙˆÙ„ÙŠØ¯ ÙÙŠØ¯ÙŠÙˆ)
- GPT-5 Ù…ØªÙˆÙ‚Ø¹ 2025

Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©:
- GitHub Copilot X
- Cursor Ùˆ Windsurf (Ù…Ø­Ø±Ø±Ø§Øª AI)
- Rust ÙÙŠ ØµØ¹ÙˆØ¯
- WebAssembly Ù…Ù†ØªØ´Ø±

Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§:
- Apple Vision Pro
- Meta Quest 3
- Neuralink (ØªØ¬Ø§Ø±Ø¨ Ø¨Ø´Ø±ÙŠØ©)
- Ø§Ù„Ø­ÙˆØ³Ø¨Ø© Ø§Ù„ÙƒÙ…ÙˆÙ…ÙŠØ© (IBM 1000+ qubit)

Ø§Ù„Ø£Ø­Ø¯Ø§Ø«:
- Ø§Ù†ØªØ®Ø§Ø¨Ø§Øª Ø£Ù…Ø±ÙŠÙƒØ§ 2024 (ÙÙˆØ² ØªØ±Ø§Ù…Ø¨)
- Ø­Ø±Ø¨ ØºØ²Ø© 2023-2024
- Ø£ÙˆÙ„Ù…Ø¨ÙŠØ§Ø¯ Ø¨Ø§Ø±ÙŠØ³ 2024
`;

// Ù‡ÙˆÙŠØ© SevenAI
const IDENTITY = {
  name: "SevenAI",
  creator: "Ù„ÙŠØ« Ø§Ù„Ù†Ø³Ø±",
  company: "Seven_code7",
  personality: "Ø°ÙƒÙŠØŒ Ù„Ø·ÙŠÙØŒ Ù…Ø­Ø¨ Ù„Ù„Ø¥Ø³Ù„Ø§Ù… ÙˆØ§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ø±ÙˆØ­ Ø¯Ø¹Ø§Ø¨Ø© Ø®ÙÙŠÙØ©",
  tone: "ÙˆØ¯ÙˆØ¯ØŒ Ù…ØªÙˆØ§Ø¶Ø¹ØŒ Ø°ÙƒÙŠØŒ Ù…Ø±Ø­ Ø¹Ù†Ø¯ Ø§Ù„Ù„Ø²ÙˆÙ…",
  values: ["Ø§Ù„ØµØ¯Ù‚", "Ø§Ù„Ø¯Ù‚Ø©", "Ø§Ù„Ø§Ø­ØªØ±Ø§Ù…", "Ø§Ù„ØªØ¹Ø§ÙˆÙ†", "Ø§Ù„Ù…Ø±ÙˆÙ†Ø©"]
};

// Ø¨Ù†Ø§Ø¡ Few-shot Prompt
function buildFewShotPrompt(
  userQuery: string,
  userFacts: string[],
  includeIdentity: boolean = false
): Array<{ role: "system" | "user" | "assistant"; content: string }> {
  
  const messages: Array<{ role: "system" | "user" | "assistant"; content: string }> = [];
  
  // System prompt
  let systemPrompt = `Ø£Ù†Øª ${IDENTITY.name}ØŒ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¹Ø±Ø¨ÙŠ Ù…ØªÙ‚Ø¯Ù….

Ø§Ù„Ø´Ø®ØµÙŠØ©: ${IDENTITY.personality}
Ø§Ù„Ø£Ø³Ù„ÙˆØ¨: ${IDENTITY.tone}
Ø§Ù„Ù‚ÙŠÙ…: ${IDENTITY.values.join("ØŒ ")}

Ù‚ÙˆØ§Ø¹Ø¯:
1. Ø§Ø­ØªØ±Ø§Ù… Ø§Ù„Ø¬Ù…ÙŠØ¹
2. Ø¹Ø¯Ù… Ø§Ù„ÙƒØ°Ø¨
3. Ø§Ù„ÙØ®Ø± Ø¨Ø§Ù„Ø¥Ø³Ù„Ø§Ù… ÙˆÙÙ„Ø³Ø·ÙŠÙ†
4. Ø¯Ø¹Ø§Ø¨Ø© Ø°ÙƒÙŠØ©
5. Ø±Ø¯ÙˆØ¯ Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙˆØ§Ø¶Ø­Ø©`;

  if (includeIdentity) {
    systemPrompt += `\n\nÙ…Ø¹Ù„ÙˆÙ…Ø§ØªÙƒ:\n- Ø§Ù„Ù…Ø·ÙˆØ±: ${IDENTITY.creator}\n- Ø§Ù„Ø´Ø±ÙƒØ©: ${IDENTITY.company}`;
  }

  systemPrompt += `\n\n${KNOWLEDGE_2024_2025}`;

  if (userFacts.length > 0) {
    systemPrompt += `\n\nÙ…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:\n${userFacts.join("\n")}`;
  }

  messages.push({ role: "system", content: systemPrompt });

  // Ø¥Ø¶Ø§ÙØ© Ø£Ù…Ø«Ù„Ø© Few-shot (3-5 Ø£Ù…Ø«Ù„Ø©)
  const selectedExamples = TRAINING_EXAMPLES.slice(0, 5);
  for (const example of selectedExamples) {
    messages.push({ role: "user", content: example.user });
    messages.push({ role: "assistant", content: example.assistant });
  }

  return messages;
}

// Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… (Advanced Deep Thinking)
async function deepThinking(query: string): Promise<{
  thinking: string;
  answer: string;
}> {
  try {
    // Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
    const { advancedDeepThinking, formatThinkingProcess } = await import('./advanced-thinking');
    
    const result = await advancedDeepThinking(query);
    
    return {
      thinking: formatThinkingProcess(result),
      answer: result.answer,
    };
  } catch (error) {
    console.error('[Deep Thinking] Error:', error);
    
    // Fallback Ù„Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
    const thinkingPrompt = `Ø£Ù†Øª SevenAI ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚.

Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©:
"${query}"

ÙÙƒØ± Ø¨ØµÙˆØª Ø¹Ø§Ù„Ù:
1. Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŸ
2. Ù…Ø§ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©ØŸ
3. ÙƒÙŠÙ Ø£Ø¨Ù†ÙŠ Ø¥Ø¬Ø§Ø¨Ø© Ø´Ø§Ù…Ù„Ø©ØŸ

Ø§ÙƒØªØ¨ ØªÙÙƒÙŠØ±Ùƒ Ø¨Ø§Ù„ØªÙØµÙŠÙ„.`;

    const thinkingResponse = await invokeLLM({
      messages: [{ role: "user", content: thinkingPrompt }],
    });

    const thinking = typeof thinkingResponse.choices[0]?.message?.content === 'string'
      ? thinkingResponse.choices[0].message.content
      : "Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±...";

    const answerPrompt = `Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„ØªÙÙƒÙŠØ±:
${thinking}

Ø§Ù„Ø¢Ù† Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø´ÙƒÙ„ Ø´Ø§Ù…Ù„ ÙˆÙ…ÙØµÙ„:
"${query}"`;

    const answerResponse = await invokeLLM({
      messages: [{ role: "user", content: answerPrompt }],
    });

    const answer = typeof answerResponse.choices[0]?.message?.content === 'string'
      ? answerResponse.choices[0].message.content
      : "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£.";

    return { thinking, answer };
  }
}

// Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
export async function processWithLlama(
  userId: number,
  query: string,
  conversationHistory: Array<{ role: string; content: string }>,
  useDeepThinking: boolean = false
): Promise<{
  response: string;
  status: "success" | "blocked";
  thinkingProcess?: string;
}> {
  
  try {
    // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù‡ÙˆÙŠØ©
    const includeIdentity = /Ù…Ù† Ø£Ù†Øª|Ù…Ù† ØµÙ†Ø¹Ùƒ|Ù…Ù† Ø·ÙˆØ±Ùƒ|who are you/i.test(query);
    
    // Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø­Ù‚Ø§Ø¦Ù‚ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    const userFactsData = await getUserFacts(userId);
    const userFacts = userFactsData.map(f => `- ${f.factType}: ${f.factValue}`);
    
    // Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚
    if (useDeepThinking) {
      const { thinking, answer } = await deepThinking(query);
      return {
        response: answer,
        status: "success",
        thinkingProcess: `ğŸ§  Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚:\n\n${thinking}`
      };
    }
    
    // Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ© Ù…Ø¹ Few-shot
    const messages = buildFewShotPrompt(query, userFacts, includeIdentity);
    
    // Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø¢Ø®Ø± 8 Ø±Ø³Ø§Ø¦Ù„)
    const recentHistory = conversationHistory.slice(-8);
    for (const msg of recentHistory) {
      if (msg.role === "user" || msg.role === "assistant") {
        messages.push({
          role: msg.role as "user" | "assistant",
          content: msg.content
        });
      }
    }
    
    // Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ
    messages.push({ role: "user", content: query });
    
    // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    const response = await invokeLLM({ messages });
    
    const content = response.choices[0]?.message?.content;
    const assistantMessage = typeof content === 'string' 
      ? content 
      : "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£.";
    
    return {
      response: assistantMessage,
      status: "success"
    };
    
  } catch (error) {
    console.error("[Llama Engine] Error:", error);
    return {
      response: "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
      status: "success"
    };
  }
}

// ØªÙˆÙ„ÙŠØ¯ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
export async function generateTitle(firstMessage: string): Promise<string> {
  try {
    const response = await invokeLLM({
      messages: [
        {
          role: "system",
          content: "ÙˆÙ„Ù‘Ø¯ Ø¹Ù†ÙˆØ§Ù†Ø§Ù‹ Ù‚ØµÙŠØ±Ø§Ù‹ (3-5 ÙƒÙ„Ù…Ø§Øª) Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø©. Ø§Ù„Ø±Ø¯ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙÙ‚Ø·."
        },
        {
          role: "user",
          content: `Ø¹Ù†ÙˆØ§Ù† Ù„Ù€: "${firstMessage}"`
        }
      ],
    });

    const content = response.choices[0]?.message?.content;
    return typeof content === 'string' ? content.trim().substring(0, 50) : "Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©";
  } catch (error) {
    return "Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©";
  }
}
